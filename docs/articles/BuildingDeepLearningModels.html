<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Building Deep Learning Models • PatientLevelPrediction</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Building Deep Learning Models">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">PatientLevelPrediction</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">3.0.5</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/PatientLevelPrediction.html">Get started</a>
</li>
<li>
  <a href="../articles/Videos.html">Videos</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/AddingCustomAlgorithms.html">Adding Custom Patient-Level Prediction Algorithms</a>
    </li>
    <li>
      <a href="../articles/BuildingDeepLearningModels.html">Building Deep Learning Models</a>
    </li>
    <li>
      <a href="../articles/BuildingEnsembleModels.html">Building Ensemble Models</a>
    </li>
    <li>
      <a href="../articles/BuildingMultiplePredictiveModels.html">Automatically Build Multiple Patient-Level Predictive Models</a>
    </li>
    <li>
      <a href="../articles/BuildingPredictiveModels.html">Building patient-level predictive models</a>
    </li>
    <li>
      <a href="../articles/CreatingNetworkStudies.html">Making  patient-level predictive network study packages</a>
    </li>
    <li>
      <a href="../articles/GeneratingLearningCurves.html">Generating Learning Curves</a>
    </li>
    <li>
      <a href="../articles/ImplementingExistingModels.html">Implementing Existing Prediction Models using the OHDSI PatientLevelPrediction Framework</a>
    </li>
    <li>
      <a href="../articles/InstallationGuide.html">Patient-Level Prediction Installation Guide</a>
    </li>
    <li>
      <a href="../articles/Videos.html">Demo Videos</a>
    </li>
  </ul>
</li>
<li>
  <a href="https://www.ohdsi.org/past-events/patient-level-prediction/">Tutorial</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/OHDSI/PatientLevelPrediction">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Building Deep Learning Models</h1>
                        <h4 class="author">Peter R. Rijnbeek, Seng Chan You, Xiaoyong Pan, Jenna Reps</h4>
            
            <h4 class="date">2019-05-30</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/OHDSI/PatientLevelPrediction/blob/master/vignettes/BuildingDeepLearningModels.Rmd"><code>vignettes/BuildingDeepLearningModels.Rmd</code></a></small>
      <div class="hidden name"><code>BuildingDeepLearningModels.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>Electronic Health Records (EHR) data is high dimensional, heterogeneous, and sparse, which makes predictive modelling a challenge. In the early days, the machine learning community mainly focused on algorithm development, currently there is a shift to more powerful feature engineering. Deep Learning models are widely used to automatically learn high-level feature representations from the data, and have achieved remarkable results in image processing, speech recognition and computational biology. Recently, interesting results have been shown using EHRs, but more extensive research is needed to assess the power of Deep Learning in this domain.</p>
<p>This vignette describes how you can use the Observational Health Data Sciences and Informatics (OHDSI) <a href="http://github.com/OHDSI/PatientLevelPrediction"><code>PatientLevelPrediction</code></a> package to build Deep Learning models. This vignette assumes you have read and are comfortable with building patient level prediction models as described in the <a href="https://github.com/OHDSI/PatientLevelPrediction/blob/master/inst/doc/BuildingPredictiveModels.pdf"><code>BuildingPredictiveModels</code> vignette</a>. Furthermore, this vignette assumes you are familiar with Deep Learning methods.</p>
</div>
<div id="background" class="section level1">
<h1 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h1>
<p>Deep Learning models are build by stacking an often large number of neural network layers that perform feature engineering steps, e.g embedding, and are collapsed in a final softmax layer (basically a logistic regression layer). These algorithms need a lot of data to converge to a good representation, but currently the sizes of the EHR databases are growing fast which would make Deep Learning an interesting approach to test within OHDSI’s <a href="https://academic.oup.com/jamia/article/25/8/969/4989437">Patient-Level Prediction Framework</a>. The current implementation allows us to perform research at scale on the value and limitations of Deep Learning using EHR data. For relatively small Target and Outcome cohorts, Deep Learning is most probably not the best choice.</p>
<p>Most current Deep Learning research is performed in python and we have developed a pipeline to interact with python. Multiple Deep Learning backends have been developed, e.g. Tensorflow, PyTorch, Keras (recently also available in R) etc. In the package we have implemented interaction with Keras in R and PyTorch in Python but we invite the community to add other backends.</p>
<p>Many network architectures have recently been proposed and we have implemented a number of them, however, this list will grow in the near future. It is important to understand that some of these architectures require a 2D data matrix, i.e. |patient|x|feature|, and others use a 3D data matrix |patient|x|feature|x|time|. The <a href="www.github.com%5Cohdsi%5CFeatureExtraction">FeatureExtraction Package</a> has been extended to enable the extraction of both data formats as will be described with examples below.</p>
<p>Note that training Deep Learning models is computationally intensive, our implementation therefore supports both GPU and CPU. It will automatically check whether there is GPU or not in your computer. A GPU is highly recommended for Deep Learning!</p>
</div>
<div id="non-temporal-architectures" class="section level1">
<h1 class="hasAnchor">
<a href="#non-temporal-architectures" class="anchor"></a>Non-Temporal Architectures</h1>
<p>We implemented the following non-temporal (2D data matrix) architectures using PyTorch:</p>
<pre><code>1) Logistics regression (LRTorch)
   A simple softmax layer with l2 regularization

2) Feed forward network (MLPTorch) 
   Supports multilayer perceptron (mlp_type = MLP) and 
   Self-Normalizing Neural Networks (mlp_type = SNN)
   Reference: https://arxiv.org/abs/1706.02515</code></pre>
<p>For the above two methods, we implemented support for a stacked autoencoder and a variational autoencoder to reduce the feature dimension as a first step. These autoencoders learn efficient data encodings in an unsupervised manner by stacking multiple layers in a neural network. Compared to the standard implementations of LR and MLP these implementations can use the GPU power to speed up the gradient descent approach in the back propagation to optimize the weights of the classifier.</p>
<p>Table 1: Non-Temporal Deep Learning Models Hyper-Parameters</p>
<table class="table">
<colgroup>
<col width="12%">
<col width="37%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>Name</th>
<th>Description</th>
<th>Hyper-parameters</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>LRTorch</td>
<td>Logistic Regression Model</td>
<td>w_decay (l2 regularization), epochs (number of epochs), class_weight (0 = inverse ratio between number of positive and negative examples, -1 = focal loss (<a href="https://arxiv.org/abs/1708.02002" class="uri">https://arxiv.org/abs/1708.02002</a>), or other), autoencoder (apply stacked autoencoder?, vae (apply variational autoencoder)</td>
</tr>
<tr class="even">
<td>MLPTorch</td>
<td>Multi-Layer Perceptron Model</td>
<td>mlp_type (MLP = default, SNN = self-normalizing neural network), size (number of hidden nodes), w_decay (l2 regularization), epochs (number of epochs), class_weight(0 = inverse ratio between number of positive and negative examples, -1 = focal loss, or other), autoencoder (apply stacked autoencoder), vae (apply variational autoencoder?)</td>
</tr>
</tbody>
</table>
<div id="example" class="section level2">
<h2 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h2>
<p>The approach for logistic regression (LRTorch) and the Multi-Layer Perceptron (MLPTorch) is identical. Here we will take LRTorch as an example.</p>
<p>You need to generate a <code>population</code> and <code>plpData</code> object as described in more detail in <a href="https://github.com/OHDSI/PatientLevelPrediction/blob/master/inst/doc/BuildingPredictiveModels.pdf"><code>BuildingPredictiveModels</code> vignette</a>.</p>
<p>Alternatively, you can make use of the data simulator. The following code snippet creates a population of 12000 patients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/Random">set.seed</a></span>(<span class="dv">1234</span>)
<span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/data">data</a></span>(plpDataSimulationProfile)
sampleSize &lt;-<span class="st"> </span><span class="dv">12000</span>
plpData &lt;-<span class="st"> </span><span class="kw"><a href="../reference/simulatePlpData.html">simulatePlpData</a></span>(
  plpDataSimulationProfile,
  <span class="dt">n =</span> sampleSize
)

population &lt;-<span class="st"> </span><span class="kw"><a href="../reference/createStudyPopulation.html">createStudyPopulation</a></span>(
  plpData,
  <span class="dt">outcomeId =</span> <span class="dv">2</span>,
  <span class="dt">binary =</span> <span class="ot">TRUE</span>,
  <span class="dt">firstExposureOnly =</span> <span class="ot">FALSE</span>,
  <span class="dt">washoutPeriod =</span> <span class="dv">0</span>,
  <span class="dt">removeSubjectsWithPriorOutcome =</span> <span class="ot">FALSE</span>,
  <span class="dt">priorOutcomeLookback =</span> <span class="dv">99999</span>,
  <span class="dt">requireTimeAtRisk =</span> <span class="ot">FALSE</span>,
  <span class="dt">minTimeAtRisk =</span> <span class="dv">0</span>,
  <span class="dt">riskWindowStart =</span> <span class="dv">0</span>,
  <span class="dt">addExposureDaysToStart =</span> <span class="ot">FALSE</span>,
  <span class="dt">riskWindowEnd =</span> <span class="dv">365</span>,
  <span class="dt">addExposureDaysToEnd =</span> <span class="ot">FALSE</span>,
  <span class="dt">verbosity =</span> <span class="st">"INFO"</span>
)</code></pre></div>
<p>As an example we will build a LRTorch model. We could specify the stacked autoencoder or the variational autoencoder to be used for reducing the feature dimension as an initial layer, but for this example we do not.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">autoencoder &lt;-<span class="st"> </span><span class="ot">FALSE</span>
vae &lt;-<span class="st"> </span><span class="ot">FALSE</span></code></pre></div>
<p>We added a class_weight for imbalanced data, the default value 0 is the inverse ratio between negatives and positives,-1 applies focal loss.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">class_weight &lt;-<span class="st"> </span><span class="dv">0</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Specify the settings for Logistics regression model using Torch in Python</span>
model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/setLRTorch.html">setLRTorch</a></span>(<span class="dt">autoencoder=</span>autoencoder, <span class="dt">vae=</span>vae,  <span class="dt">class_weight=</span>class_weight)</code></pre></div>
<p>No we define our modelling parameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testFraction &lt;-<span class="st"> </span><span class="fl">0.2</span>
testSplit &lt;-<span class="st"> 'person'</span>
nfold &lt;-<span class="st"> </span><span class="dv">3</span>
splitSeed &lt;-<span class="st"> </span><span class="dv">1000</span></code></pre></div>
<p>And we train and internally validate the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span>PatientLevelPrediction<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/PatientLevelPrediction/topics/runPlp">runPlp</a></span>(<span class="dt">population =</span> population, 
                                          <span class="dt">plpData =</span> plpData, 
                                          <span class="dt">modelSettings =</span> model,
                                          <span class="dt">testSplit=</span>testSplit,
                                          <span class="dt">testFraction=</span>testFraction,
                                          <span class="dt">nfold=</span>nfold, 
                                          <span class="dt">splitSeed=</span>splitSeed) </code></pre></div>
</div>
</div>
<div id="temporal-architectures" class="section level1">
<h1 class="hasAnchor">
<a href="#temporal-architectures" class="anchor"></a>Temporal Architectures</h1>
<p>Several architectures are implemented that can handle temporal data in PyTorch and R Keras.</p>
<div id="pytorch-cnn" class="section level2">
<h2 class="hasAnchor">
<a href="#pytorch-cnn" class="anchor"></a>PyTorch CNN</h2>
<p>We implemented the following <strong>convolutional</strong> models described in <a href="https://github.com/clinicalml/deepDiagnosis" class="uri">https://github.com/clinicalml/deepDiagnosis</a> in CNNTorch:</p>
<ol style="list-style-type: decimal">
<li><dl>
<dt>
Temporal Convolutional neural network over a backward window (type = cnn)
</dt>
<dd>
<img src="arch1.png">
</dd>
</dl></li>
<li><dl>
<dt>
Convolutional neural network over input and time dimension (type = mix)
</dt>
<dd>
<img src="conv_arch2.png">
</dd>
</dl></li>
<li><dl>
<dt>
Multi-resolution temporal convolutional neural network (type = multi)
</dt>
<dd>
<img src="conv_arch1.png">
</dd>
</dl></li>
</ol>
<p>Furthermore, we added the following achitectures:</p>
<ol start="4" style="list-style-type: decimal">
<li><dl>
<dt>
CNN with filters with three different parallel kernel sizes (3,4,5) and a fully connected layers (type = mlf)
</dt>
<dd>
<img src="cnn_mlf2.png">
</dd>
</dl></li>
<li>
<dt>
LSTM network over the backward window (type = lstm)
</dt>
<dd>
<img src="cnn_lstm.png">
</dd>
</li>
<li>
<dt>
Residual Learning Network as described in: <a href="https://arxiv.org/abs/1512.03385" class="uri">https://arxiv.org/abs/1512.03385</a> (type = resnet)
</dt>
<dd>
This a very big network, see the paper for the topology.
</dd>
</li>
</ol>
<table class="table">
<colgroup>
<col width="15%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th>parameter</th>
<th>description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>nbfilters</td>
<td>The number of convolution filters</td>
</tr>
<tr class="even">
<td>epochs</td>
<td>The number of epochs</td>
</tr>
<tr class="odd">
<td>seed</td>
<td>Random seed</td>
</tr>
<tr class="even">
<td>class_weight</td>
<td>The class weight used for imbalanced data <br> (0: Inverse ratio between positives and negatives, -1: Focal loss, or number)</td>
</tr>
</tbody>
</table>
</div>
<div id="pytorch-rnn" class="section level2">
<h2 class="hasAnchor">
<a href="#pytorch-rnn" class="anchor"></a>PyTorch RNN</h2>
<p>The following <strong>recurrent neural network</strong> models are implemented in RNNTorch:</p>
<ol style="list-style-type: decimal">
<li><dl>
<dt>
RNN with one LSTM layer fed into one fully connected layer (type = RNN)
</dt>
<dd>
<dd>
<img src="lstm_last.png">
</dd>
</dd>
</dl></li>
<li><dl>
<dt>
RNN with one bidirectional LSTM layer fed into one fully connected layer (type = BiRNN)
</dt>
<dd>
This network looks the same as above but then as a bi-directional version
</dd>
</dl></li>
<li><dl>
<dt>
One Gated Recurrent Unit layer fed into one fully connected layers (type = GRU)
</dt>
<dd>
This network looks the same as above but then implemented as GRU
</dd>
</dl></li>
</ol>
<p>The following hyper-parameters can be set for these PyTorch models:</p>
<table class="table">
<colgroup>
<col width="15%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th>parameter</th>
<th>description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>hidden_size</td>
<td>The number of features in hidden state</td>
</tr>
<tr class="even">
<td>epochs</td>
<td>The number of epochs</td>
</tr>
<tr class="odd">
<td>seed</td>
<td>Random seed</td>
</tr>
<tr class="even">
<td>class_weight</td>
<td>The class weight used for imbalanced data <br> (0: Inverse ratio between positives and negatives, -1: Focal loss, or number)</td>
</tr>
</tbody>
</table>
</div>
<div id="r-keras-cnn" class="section level2">
<h2 class="hasAnchor">
<a href="#r-keras-cnn" class="anchor"></a>R Keras CNN</h2>
<p>The following temporal architectures as described in <a href="https://arxiv.org/pdf/1608.00647.pdf" class="uri">https://arxiv.org/pdf/1608.00647.pdf</a> were implemented using R Keras:</p>
<ol style="list-style-type: decimal">
<li><dl>
<dt>
Multi-resolution CovNN model (CovNN.R)
</dt>
<dd>
<img src="CovCNN.png">
</dd>
</dl></li>
<li><dl>
<dt>
Convolution across data and time according(CovNN2.R)
</dt>
<dd>
<img src="covcnn2.png">
</dd>
</dl></li>
</ol>
<p>Furthermore, a custom build RNN is added that uses a variational autoencoder.</p>
<ol start="3" style="list-style-type: decimal">
<li><dl>
<dt>
Clinically Informing application based on Recurrent Neural Network (CIReNN.R)
</dt>
<dd>
<img src="cirenn.png">
</dd>
</dl></li>
</ol>
<p>Table 2: Temporal Deep Learning Models</p>
<table class="table">
<colgroup>
<col width="12%">
<col width="87%">
</colgroup>
<thead><tr class="header">
<th>Model</th>
<th>Hyper-parameters</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>CovNN</td>
<td>batchSize (The number of samples to used in each batch during model training), outcomeWeight (The weight assigned to the outcome), lr (The learning rate), decay (The decay of the learning rate), dropout ([currently not used] the dropout rate for regularization), epochs (The number of times data is used to train the model, e.g., epoches=1 means data only used once to train), filters (The number of columns output by each convolution), kernelSize (The number of time dimensions used for each convolution), loss (The loss function implemented), seed (The random seed)</td>
</tr>
<tr class="even">
<td>CovNN2</td>
<td>batchSize (The number of samples to used in each batch during model training), outcomeWeight (The weight assigned to the outcome), lr (The learning rate), decay (The decay of the learning rate), dropout ([currently not used] the dropout rate for regularization), epochs (The number of times data is used to train the model, e.g., epoches=1 means data only used once to train), filters (The number of columns output by each convolution), kernelSize (The number of time dimensions used for each convolution), loss (The loss function implemented), seed (The random seed)</td>
</tr>
<tr class="odd">
<td>CIReNN</td>
<td>units (The number of units of RNN layer - as a list of vectors), recurrentDropout (The reccurrent dropout rate), layerDropout (The layer dropout rate), lr (Learning rate), decay (Learning rate decay over each update), outcomeWeight (The weight of the outcome class in the loss function), batchSize (The number of data points to use per training batch), epochs (Number of times to iterate over data set), earlyStoppingMinDelta (Minimum change in the monitored quantity to qualify as an improvement for early stopping, i.e. an absolute change of less than min_delta in loss of validation data, will count as no improvement), earlyStoppingPatience (Number of epochs with no improvement after which training will be stopped), seed (Random seed used by Deep Learning model)</td>
</tr>
</tbody>
</table>
</div>
<div id="example-1" class="section level2">
<h2 class="hasAnchor">
<a href="#example-1" class="anchor"></a>Example</h2>
<p>We will now show how to use the temporal models by using CNNTorch as an example.</p>
<p>You need to generate a <code>population</code> and <code>plpData</code> object as described in more detail in <a href="https://github.com/OHDSI/PatientLevelPrediction/blob/master/inst/doc/BuildingPredictiveModels.pdf"><code>BuildingPredictiveModels</code> vignette</a>.</p>
<p>Note that for these algorithms you need to extracted temporal data as described in the [FeatureExtraction vignette] (<a href="https://github.com/OHDSI/FeatureExtraction/blob/master/inst/doc/UsingFeatureExtraction.pdf" class="uri">https://github.com/OHDSI/FeatureExtraction/blob/master/inst/doc/UsingFeatureExtraction.pdf</a>) as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">settings &lt;-<span class="st"> </span><span class="kw">createTemporalCovariateSettings</span>(<span class="dt">useConditionEraStart =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useConditionEraOverlap =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useConditionOccurrence =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useConditionEraGroupStart =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useConditionEraGroupOverlap =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useDrugExposure =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useDrugEraStart =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useDrugEraOverlap =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useMeasurement =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useMeasurementValue =</span> <span class="ot">TRUE</span>,
                                            <span class="dt">useMeasurementRangeGroup =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useProcedureOccurrence =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useDeviceExposure =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">useObservation =</span> <span class="ot">FALSE</span>,
                                            <span class="dt">excludedCovariateConceptIds =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="dv">316866</span>),
                                            <span class="dt">addDescendantsToExclude =</span> <span class="ot">TRUE</span>,
                                            <span class="dt">temporalStartDays =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/seq">seq</a></span>(<span class="dt">from =</span> <span class="op">-</span><span class="dv">365</span>, 
                                                                    <span class="dt">to =</span> <span class="op">-</span><span class="dv">1</span>, <span class="dt">by =</span> <span class="dv">12</span>), 
                                            <span class="dt">temporalEndDays =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/seq">seq</a></span>(<span class="dt">from =</span> <span class="op">-</span><span class="dv">353</span>, 
                                                                    <span class="dt">to =</span> <span class="dv">0</span>, <span class="dt">by =</span> <span class="dv">12</span>), <span class="dv">0</span>))

plpData &lt;-<span class="st"> </span><span class="kw"><a href="../reference/getPlpData.html">getPlpData</a></span>(<span class="dt">connectionDetails =</span> connectionDetails,
                        <span class="dt">cdmDatabaseSchema =</span> cdmDatabaseSchema,
                        <span class="dt">cohortDatabaseSchema =</span> <span class="st">"results"</span>,
                        <span class="dt">cohortTable =</span> <span class="st">"cohort"</span>,
                        <span class="dt">cohortId =</span> <span class="dv">11</span>,
                        <span class="dt">covariateSettings =</span> settings,
                        <span class="dt">outcomeDatabaseSchema =</span> resultsDatabaseSchema,
                        <span class="dt">outcomeTable =</span> <span class="st">"cohort"</span>,
                        <span class="dt">outcomeIds =</span> <span class="dv">25</span>,
                        <span class="dt">cdmVersion =</span> <span class="dv">5</span>)</code></pre></div>
<p>Each CNN/RNN has several hyper-parameters that can be set as shown in the Tables above, but for this example we take the defaults.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># specify the the CNN</span>
model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/setCNNTorch.html">setCNNTorch</a></span>(<span class="dt">cnn_type=</span><span class="st">'CNN'</span>)</code></pre></div>
<p>Run the model training, for example with a testFraction = 0.2 and a split by person:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span>PatientLevelPrediction<span class="op">::</span><span class="kw"><a href="https://www.rdocumentation.org/packages/PatientLevelPrediction/topics/runPlp">runPlp</a></span>(population, plpData, model,
                                          <span class="dt">testSplit=</span><span class="st">'person'</span>,
                                          <span class="dt">testFraction=</span><span class="fl">0.2</span>,
                                          <span class="dt">nfold=</span><span class="dv">3</span>, 
                                          <span class="dt">splitSeed=</span><span class="dv">1000</span>) </code></pre></div>
</div>
</div>
<div id="apply-the-trained-deep-learning-model" class="section level1">
<h1 class="hasAnchor">
<a href="#apply-the-trained-deep-learning-model" class="anchor"></a>Apply the trained Deep Learning model</h1>
<p>Applying a Deep Learning is identical to the other models in the package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the trained model</span>
plpModel &lt;-<span class="st"> </span><span class="kw"><a href="../reference/loadPlpModel.html">loadPlpModel</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/getwd">getwd</a></span>(), <span class="st">"&lt;your model&gt;"</span>)

<span class="co"># load the new plpData (should have the same temporal features!) and create the population</span>
plpData &lt;-<span class="st"> </span><span class="kw"><a href="../reference/loadPlpData.html">loadPlpData</a></span>(<span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/getwd">getwd</a></span>(), <span class="st">"&lt;your data&gt;"</span>)

populationSettings &lt;-<span class="st"> </span>plpModel<span class="op">$</span>populationSettings
populationSettings<span class="op">$</span>plpData &lt;-<span class="st"> </span>plpData
population &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/do.call">do.call</a></span>(createStudyPopulation, populationSettings)  

<span class="co"># apply the trained model on the new data</span>
validationResults &lt;-<span class="st"> </span><span class="kw"><a href="../reference/applyModel.html">applyModel</a></span>(population, plpData, plpModel)</code></pre></div>
</div>
<div id="adding-new-architectures" class="section level1">
<h1 class="hasAnchor">
<a href="#adding-new-architectures" class="anchor"></a>Adding new architectures</h1>
<p>It is possible to add new architectures in our framework using PyTorch or R Keras. We are happy to help you with this, please post your questions on the <a href="www.github.com/OHDSI/PatientLevelPrediction/issues">issue tracker</a> of the package.</p>
</div>
<div id="acknowledgments" class="section level1">
<h1 class="hasAnchor">
<a href="#acknowledgments" class="anchor"></a>Acknowledgments</h1>
<p>Considerable work has been dedicated to provide the <code>PatientLevelPrediction</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/utils/topics/citation">citation</a></span>(<span class="st">"PatientLevelPrediction"</span>)</code></pre></div>
<pre><code>## 
## To cite PatientLevelPrediction in publications use:
## 
## Reps JM, Schuemie MJ, Suchard MA, Ryan PB, Rijnbeek P (2018).
## "Design and implementation of a standardized framework to generate
## and evaluate patient-level prediction models using observational
## healthcare data." _Journal of the American Medical Informatics
## Association_, *25*(8), 969-975. &lt;URL:
## https://doi.org/10.1093/jamia/ocy032&gt;.
## 
## A BibTeX entry for LaTeX users is
## 
##   @Article{,
##     author = {J. M. Reps and M. J. Schuemie and M. A. Suchard and P. B. Ryan and P. Rijnbeek},
##     title = {Design and implementation of a standardized framework to generate and evaluate patient-level prediction models using observational healthcare data},
##     journal = {Journal of the American Medical Informatics Association},
##     volume = {25},
##     number = {8},
##     pages = {969-975},
##     year = {2018},
##     url = {https://doi.org/10.1093/jamia/ocy032},
##   }</code></pre>
<p><strong>Please reference this paper if you use the PLP Package in your work:</strong></p>
<p><a href="http://dx.doi.org/10.1093/jamia/ocy032">Reps JM, Schuemie MJ, Suchard MA, Ryan PB, Rijnbeek PR. Design and implementation of a standardized framework to generate and evaluate patient-level prediction models using observational healthcare data. J Am Med Inform Assoc. 2018;25(8):969-975.</a></p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#background">Background</a></li>
      <li>
<a href="#non-temporal-architectures">Non-Temporal Architectures</a><ul class="nav nav-pills nav-stacked">
<li><a href="#example">Example</a></li>
      </ul>
</li>
      <li>
<a href="#temporal-architectures">Temporal Architectures</a><ul class="nav nav-pills nav-stacked">
<li><a href="#pytorch-cnn">PyTorch CNN</a></li>
      <li><a href="#pytorch-rnn">PyTorch RNN</a></li>
      <li><a href="#r-keras-cnn">R Keras CNN</a></li>
      <li><a href="#example-1">Example</a></li>
      </ul>
</li>
      <li><a href="#apply-the-trained-deep-learning-model">Apply the trained Deep Learning model</a></li>
      <li><a href="#adding-new-architectures">Adding new architectures</a></li>
      <li><a href="#acknowledgments">Acknowledgments</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Jenna Reps, Martijn Schuemie, Marc Suchard, Patrick Ryan, Peter Rijnbeek.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
